# 介绍

> `es`聚合分析优势
>
> 1. 功能丰富，提供`Bucket`, `Metric`, `Pipeline`等多种分析方式，可以满足大部分的分析需求
> 2. 实时性高，所有的计算结果都是即时返回的，而`hadoop`等大数据系统一般都是`T + 1`级别的



![](/home/wangzheng/文档/notes/image/聚合分析api概览.png)

```http
GET test_search_index/_search
{
	"size": 0,  # 不需要返回文档列表
	"aggs": {
		"people_per_job": {
			"terms": {
				"field": "job.keyword"
			}
		}
	}
}
```

### 分类

> `es`将聚合分析主要分为如下4类
>
> 1. `Bucket`，分桶类型，类似`SQL`中的`GROUP BY`语法
> 2. `Metric`，指标分析类型，如计算最大值，最小值，平均值等等
> 3. `Pipeline`，管道分析类型，基于上一级的聚合分析结果进行再分析
> 4. `Matrix`，矩阵分析类型



# `Metric`

> 主要分2类
>
> 1. 单值分析，只输出一个分析结果
>    1. `min`, `max`, `avg`, `sum`
>    2. `cardinality`
>
> 2. 多值分析，输出多个分析结果
>    1. `stats`, `extended stats`
>    2. `percentile`, `percentile rank`
>    3. `top hits`

## 单值

### `min`, `max`, `avg`, `sum`

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"avg_age": {
			"avg": {
				"field": "age"
			}
		}
	}
}
```

多个聚合分析

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"min_age": {
			"min": {
				"field": "age"
			}
		},
		"max_age": {
			"max": {
				"field": "age"
			}
		},
		"sum_age": {
			"sum" : {
				"field": "age"
			}
		},
		"avg_age": {
			"avg": {
				"field": "age"
			}
		}
	}
}
```

### `cardinality`

> 意为集合的势，或者基数，是指计算不同数据的个数，类似`SQL`中的`distinct count`概念

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"count_of_job": {
			"cardinality": {
				"field": "job.keyword"
			}
		}
	}
}
```

## 多值

### `stats`

> 返回一系列数值类型的统计值，包含`min`, `max`, `avg`, `sum`, `count`

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"stats_age": {
			"stats": {
				"field": "age"
			}
		}
	}
}
```

### `extended stats`

> 对`stats`的扩展，包含了更多的统计数据，如方差、标准差等

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"stats_age": {
			"extended_stats": {
				"field": "age"
			}
		}
	}
}
```

### `percentiles`

> 百分位数统计

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"per_salary": {
			"percentiles": {
				"field": "salary",
				"percents": [
					95,
					99
				]
			}
		}
	}
}
```

### `percentile ranks`

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"per_salary": {
			"percentile_ranks": {
				"field": "salary",
				"values": [
					11000,
					30000
				]
			}
		}
	}
}
```

### `top hits`

> 一般用于分桶后获取该桶内最匹配的顶部文档列表，即详情数据

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"jobs": {
			"terms": {
				"field": "job.keyword",
				"size": 10
			},
			"aggs": {
				"top_employee": {
					"top_hits": {
						"size": 10,
						"sort": [
							{
								"age": {
									"order": "desc"
								}
							}
						]
					}
				}
			}
		}
	}
}
```



# `Bucket`

> 意为桶，即按照一定规则将文档分配到不同的桶中，达到分类的目的
>
> 1. `terms`
> 2. `range`
> 3. `date range`
> 4. `histogram`
> 5. `date histogram`

### `terms`

> 该分桶策略最简单，直接按照`term`来分桶，如果是`text`类型，则按照分词后的结果分桶

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"jobs": {
			"terms": {
				"field": "job.keyword",
				"size": 5
			}
		}
	}
}
```

### `range`

> 通过指定数值范围来设定分桶规则

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"salary_range": {
			"range": {
				"field": "salary",
				"ranges": [
					{
						"key": "小于10000",
						"to": 10000
					},
					{
						"from": 10000,
						"to": 20000
					},
					{
						"key": "大于20000",
						"from": 20000
					}
				]
			}
		}
	}
}
```

### `date range`

> 通过指定日期的范围来设定分桶规则

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"date_range": {
			"range": {
				"field": "birth",
				"format": "yyyy",
				"ranges": [
					{
						"from": "1980",
						"to": "1990"
					},
					{
						"from": "1990",
						"to": "2000"
					},
					{
						"from": "2000"
					}
				]
			}
		}
	}
}
```

### `histogram`

> 直方图，以固定间隔的策略来分割数据

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"salary_hist": {
			"histogram": {
				"field": "salary",
				"interval": 5000,
				"extended_bounds": {
					"min": 0,
					"max": 40000
				}
			}
		}
	}
}
```

> `interval`: 指定间隔大小
>
> `extended_bounds`: 指定数据范围

### `date histogram`

> 针对日期的直方图或者柱状图，是时序数据分析中常用的聚合分析类型

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"by_year": {
			"date_histogram": {
				"field": "birth",
				"interval": "year",
				"format": "yyyy"
			}
		}
	}
}
```



# `bucket + metric`聚合分析

> `bucket`聚合分析允许通过添加子分析来进一步进行分析，该子分析可以是`bucket`也可以是`metric`，这也使得`es`的聚合分析能力变得异常强大

### 分桶后再分桶

```http
GET test_search_index/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "age_range": {
          "range": {
            "field": "age",
            "ranges": [
              {
                "to": 20
              },
              {
                "from": 20,
                "to": 30
              },
              {
                "from": 30
              }
            ]
          }
        }
      }
    }
  }
}
```

### 分桶后进行数据分析

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"jobs": {
			"terms": {
				"field": "job.keyword",
				"size": 10
			},
			"aggs": {
				"salary": {
					"stats": {
						"field": "salary"
					}
				}
			}
		}
	}
}
```



# `Pipeline`

> 追对聚合分析的结果再次进行聚合分析，而且支持链式调用，可以回答如下问题
>
> 订单月平均销售额是多少?

```http
POST order/_search
{
	"size": 0,
	"aggs": {
		"sales_per_month": {
			"date_histogram": {
				"field": "date",
				"interval": "month"
			},
			"aggs": {
				"sales": {
					"sum": {
						"field": "price"
					}
				}
			}
		},
		"avg_monthly_sales": {
			"avg_bucket": {
				"buckets_path": "sales_per_month>sales*"
			}
		}
	}
}
```

> `avg_bucket`: `Pipeline`聚合分析类型的一种
>
> `buckets_path`: 所有的`Pipeline`都有

### 概况

> `Pipeline`聚合分析结果会输出到原结果中，根据输出位置的不同，分为以下两类：
>
> 1. `Parent`结果内嵌到现有的聚合分析结果中
>    1. `derivative`
>    2. `moving average`
>    3. `cumulative sum`
>
> 2. `sibling`结果与现有聚合分析结果同级
>    1. `max/min/avg/sub bucket`
>    2. `stats/extended stats bucket`
>    3. `percentiles bucket`

### `sibling`

##### `min_bucket`, `max_bucket`, `avg_bucket`, `sub_bucket`, `stats_bucket`, `percentiles_bucket`

> 找出所有`bucket`中最小的`bucket`名称和值

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"jobs": {
			"terms": {
				"field": "job.keyword",
				"size": 10
			},
			"aggs": {
				"avg_salary": {
					"avg": {
						"field": "salary"
					}
				}
			}
		},
		"min_salary_by_job": {
			"min_bucket": {
				"buckets_path": "jobs>avg_salary"
			}
		}
	}
}
```

### `parent`

##### `derivative`

> 计算`bucket`值的导数

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"birth": {
			"date_histogram": {
				"field": "birth",
				"interval": "year",
				"min_doc_count": 0
			},
			"aggs": {
				"avg_salary": {
					"avg": {
						"field": "salary"
					}
				},
				"derivative_avg_salary": {
					"derivative": {
						"buckets_path": "avg_salary"
					}
				}
			}
		}
	}
}
```

##### `moving average`

> 计算`bucket`值的移动平均值

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"birth": {
			"date_histogram": {
				"field": "birth",
				"interval": "year",
				"min_doc_count": 0
			},
			"aggs": {
				"avg_salary": {
					"avg": {
						"field": "salary"
					}
				},
				"mavg_salary": {
					"moving_avg": {
						"buckets_path": "avg_salary"
					}
				}
			}
		}
	}
}
```

`cumulative sum`

> 计算`bucket`值的累积加和

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"birth": {
			"date_histogram": {
				"field": "birth",
				"interval": "year",
				"min_doc_count": 0
			},
			"aggs": {
				"avg_salary": {
					"avg": {
						"field": "salary"
					}
				},
				"cumulative_salary": {
					"cumulative_sum": {
						"buckets_path": "avg_salary"
					}
				}
			}
		}
	}
}
```



# 作用范围

> `es`聚合分析默认作用范围是`query`结果集，可以通过以下方式改变其作用范围
>
> 1. `filter`
> 2. `post filter`
> 3. `global`

### `filter`

> 为某个聚合分析设定过滤条件，从而在不更改整体`query`语句的情况下修改了作用范围

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"jobs_salary_small": {
			"filter": {
				"range": {
					"salary": {
						"to": 10000
					}
				}
			},
			"aggs": {
				"jobs": {
					"terms": {
						"field": "job.keyword"
					}
				}
			}
		},
		"jobs": {
			"terms": {
				"field": "job.keyword"
			}
		}
	}
}
```

### `post filter`

> 1. 作用于文档过滤，但在聚合分析后生效
>
> 2. 根据一些条件来筛选文档时会使用

```http
GET test_search_index/_search
{
	"aggs": {
		"jobs": {
			"terms": {
				"field": "job.keyword"
			}
		}
	},
	"post_filter": {
		"match": {
			"job.keyword": "java engineer"
		}
	}
}
```

### `global`

> 无视`query`的过滤条件，基于全部文档进行分析

```http
GET test_search_index/_search
{
	"query": {
		"match": {
			"job.keyword": "java engineer"
		}
	},
	"aggs": {
		"java_avg_salary": {
			"avg": {
				"field": "salary"
			}
		},
		"all": {
			"global": {},
			"aggs": {
				"avg_salary": {
					"avg": {
						"field": "salary"
					}
				}
			}
		}
	}
}
```



# 排序

> 可以使用自带的关键参数进行排序

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"jobs": {
			"terms": {
				"field": "job.keyword",
				"size": 10,
				"order": [
					{
						"_count": "asc"
					},
					{
						"_key": "desc"
					}
				]
			}
		}
	}
}
```

> `_count`文档数
>
> `_key`按照`key`值排序

```http
GET test_search_index/_search
{
  "size": 0,
  "aggs": {
    "salary_hist": {
      "histogram": {
        "field": "salary",
        "interval": 5000,
        "order": {
          "age>avg_age": "desc"
        }
      },
      "aggs": {
        "age": {
          "filter": {
            "range": {
              "age": {
                "gte": 10
              }
            }
          },
          "aggs": {
            "avg_age": {
              "avg": {
                "field": "age"
              }
            }
          }
        }
      }
    }
  }
}
```

# 计算精准度

![](/home/wangzheng/文档/notes/image/Terms并不永远准确.png)

### `Terms`不准确的解决

> 1. 设置`shard`数为1，消除数据分散的问题，但无法承载大数据量
> 2. 合理设置`shard_size`大小，即每次从`shard`上额外多获取的数据，以提升准确度

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"jobs": {
			"terms": {
				"field": "job.keyword",
				"size": 1,
				"shard_size": 10
			}
		}
	}
}
```

### `shard_size`大小的设定

> `terms`聚合返回结果中有如下两个返回值
>
> 1. `doc_count_error_upper_bound`被遗漏的`term`可能的最大值
> 2. `sub_other_doc_count`返回结果`bucket`的`term`外其他`term`的文档总数

#### `show_term_doc_count_error`

> 1. 可以查看每个`bucket`误算的最大值
>
> 2. 结果返回0表明计算准确
> 3. 默认大小: `shard_size = (size * 1.5) + 10`
> 4. 通过调整`shard_size`的大小来降低`doc_count_error_upper_bound`来提升准确度
>    1. 增大了计算量，从而降低了响应时间

```http
GET test_search_index/_search
{
	"size": 0,
	"aggs": {
		"jobs": {
			"terms": {
				"field": "job.keyword",
				"size": 2,
				"show_term_doc_count_error": true
			}
		}
	}
}
```

